{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning GLiNER\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook shows the process of fine-tuning a model from the GLiNER family on a custom dataset for improved domain-specific performance. It was drawn up as part of the [*Congruence Engine*](https://www.sciencemuseumgroup.org.uk/projects/the-congruence-engine) project (2021-4) at the Science Museum Group.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "*   **Load** a pre-prepared dataset containing synthetic (llm-generated) texts with specific named entities drawn from a sample of 19th and 20th century textile industry glossaries.\n",
        "*   **Merge** this dataset with a sample drawn from the Pile-NER dataset, in order to prevent overfitting\n",
        "* **Fine-tune** a GLiNER model using the resulting merged dataset\n",
        "* **Evaluate** the fine-tuned model\n",
        "* **Share** the model on the HuggingFace Hub.\n",
        "\n",
        "This notebook was prepared using Google Colab. Parts of the notebook were adapted with the help of Chat GPT.\n",
        "\n",
        "You can find out more about *Congruence Engine*'s experiments with NER for cultural heritage by visiting the [GitHub repository](https://github.com/congruence-engine/universal-ner-with-gliner/tree/main) for this investigation. For further information on the GLiNER family of models, please refer to the [documentation](https://github.com/urchade/GLiNER).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iI9pxhYPHVO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers==4.41\n",
        "! pip install gliner\n",
        "! pip install accelerate -U\n",
        "! pip install datasets"
      ],
      "metadata": {
        "id": "-6nahoimXRqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Merging with Pile-NER**\n",
        "\n",
        "In order to avoid 'overfitting' the finetuned model to the domain-specific model, it is a good idea to merge the training data with a sample of the data used to train the original model. In this case we will be using the [Pile-NER](https://huggingface.co/datasets/Universal-NER/Pile-NER-type) dataset that was used to train [GLiNER](https://github.com/urchade/GLiNER)."
      ],
      "metadata": {
        "id": "L0wftgKEOlz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import modules**"
      ],
      "metadata": {
        "id": "5zABVKl0W2Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import json\n",
        "import re\n",
        "import ast\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "8VUHCeGnOlN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load a subset from the Pile-NER dataset**"
      ],
      "metadata": {
        "id": "bYKfUuS8W0tV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"Universal-NER/Pile-NER-type\", split=\"train[:4000]\") #this will load 4,000 examples from the dataset, from a total of 45,900"
      ],
      "metadata": {
        "id": "e26znERVWkBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Process the dataset into the correct format for GLiNER finetuning.**\n",
        "\n",
        "This requires converting the data into the following format:\n",
        "\n",
        "{\"tokenized_text\":[\"This\", \"is\", \"a\", \"tokenized\", \"text\", \"example\"], \"ner\": [[0,0, \"pronoun\"], [3,3, \"adjective\"]]}"
      ],
      "metadata": {
        "id": "hi_zGxV_Yy79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text):\n",
        "    \"\"\"Tokenizes the input text into a list of tokens.\"\"\"\n",
        "    return re.findall(r'\\w+(?:[-_]\\w+)*|\\S', text)\n",
        "\n",
        "def extract_entity_spans(entry):\n",
        "    \"\"\"Extracts entity spans from an entry.\"\"\"\n",
        "    len_start = len(\"What describes \")\n",
        "    len_end = len(\" in the text?\")\n",
        "    entity_types, entity_texts, negative = [], [], []\n",
        "\n",
        "    for c in entry['conversations']:\n",
        "        if c['from'] == 'human' and c['value'].startswith('Text: '):\n",
        "            text = c['value'][len('Text: '):]\n",
        "            tokenized_text = tokenize_text(text)\n",
        "        elif c['from'] == 'human' and c['value'].startswith('What describes '):\n",
        "            entity_type = c['value'][len_start:-len_end]\n",
        "            entity_types.append(entity_type)\n",
        "        elif c['from'] == 'gpt' and c['value'].startswith('['):\n",
        "            if c['value'] == '[]':\n",
        "                negative.append(entity_types.pop())\n",
        "                continue\n",
        "            texts_ents = ast.literal_eval(c['value'])\n",
        "            entity_texts.extend(texts_ents)\n",
        "            num_repeat = len(texts_ents) - 1\n",
        "            entity_types.extend([entity_types[-1]] * num_repeat)\n",
        "\n",
        "    entity_spans = []\n",
        "    for j, entity_text in enumerate(entity_texts):\n",
        "        entity_tokens = tokenize_text(entity_text)\n",
        "        matches = []\n",
        "        for i in range(len(tokenized_text) - len(entity_tokens) + 1):\n",
        "            if \" \".join(tokenized_text[i:i + len(entity_tokens)]).lower() == \" \".join(entity_tokens).lower():\n",
        "                matches.append((i, i + len(entity_tokens) - 1, entity_types[j]))\n",
        "        if matches:\n",
        "            entity_spans.extend(matches)\n",
        "\n",
        "    return {\"tokenized_text\": tokenized_text, \"ner\": entity_spans, \"negative\": negative}\n",
        "\n",
        "def process_data(data):\n",
        "    \"\"\"Processes a list of data entries to extract entity spans.\"\"\"\n",
        "    all_data = [extract_entity_spans(entry) for entry in tqdm(data)]\n",
        "    return all_data\n",
        "\n",
        "def save_data_to_file(data, filepath):\n",
        "    \"\"\"Saves the processed data to a JSON file.\"\"\"\n",
        "    with open(filepath, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path_pile_ner = 'train.json'\n",
        "    data = dataset\n",
        "    processed_data = process_data(data)\n",
        "    save_data_to_file(processed_data, 'pilener_train.json')\n",
        "\n",
        "    print(\"dataset size:\", len(processed_data))"
      ],
      "metadata": {
        "id": "ZvdUMfOmXD3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the subset as a json file**"
      ],
      "metadata": {
        "id": "JIqEjRIJZJGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/pile-ner-gliner.json'\n",
        "\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(processed_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Dataset successfully saved to '{output_path}'.\")"
      ],
      "metadata": {
        "id": "-07hM-eDYc1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next, load the dataset into a pandas dataframe**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p4ialrQpNBcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_one = pd.read_json('/content/pile-ner-gliner.json')\n",
        "print(f\"Dataset ONE loaded with {len(df_one)} entries.\")\n"
      ],
      "metadata": {
        "id": "lzX7cJiBM63S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, load your training dataset and merge it with the Pile-NER subset. Ensure that your dataset has already been prepared in the correct format for finetuning GLiNER**\n",
        "\n",
        "In this case, we will use a dataset prepared by the *Congruence Engine* project via a url."
      ],
      "metadata": {
        "id": "qvg2YJcbZSYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "bDRwT3ejMJz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  df_two = pd.read_json('https://raw.githubusercontent.com/congruence-engine/universal-ner-with-gliner/refs/heads/main/datasets/full_synthetic_data_gpt_4o_6_dec.json')\n",
        "\n",
        "  print(f\"Dataset TWO loaded with {len(df_two)} entries.\")\n"
      ],
      "metadata": {
        "id": "3u-p38eiKMqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You are now ready to merge the two datasets**"
      ],
      "metadata": {
        "id": "FzqvIo0oKHIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_dataset_path = '/content/merged_dataset.json'  # Output path"
      ],
      "metadata": {
        "id": "2Qsc7PlGMFg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.concat([df_one, df_two], ignore_index=True)\n",
        "print(f\"Merged dataset contains {len(merged_df)} entries.\")"
      ],
      "metadata": {
        "id": "Hks8l6UUZzaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to list of dictionaries\n",
        "merged_data = merged_df.to_dict(orient='records')\n",
        "\n",
        "# Save to JSON file\n",
        "with open(merged_dataset_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(merged_data, f, ensure_ascii=False, indent=2)\n",
        "print(f\"Merged dataset saved to '{merged_dataset_path}'.\")"
      ],
      "metadata": {
        "id": "H9SzHbWQZ3w4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Fine-tuning**\n"
      ],
      "metadata": {
        "id": "ED8urPQ2a-Pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import modules**"
      ],
      "metadata": {
        "id": "QMLwntDobD1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from gliner import GLiNERConfig, GLiNER\n",
        "from gliner.training import Trainer, TrainingArguments\n",
        "from gliner.data_processing.collator import DataCollatorWithPadding, DataCollator\n",
        "from gliner.utils import load_config_as_namespace\n",
        "from gliner.data_processing import WordsSplitter, GLiNERDataset"
      ],
      "metadata": {
        "id": "8NAG1j8CbHs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the merged dataset, and split into training and testing**"
      ],
      "metadata": {
        "id": "NIOJw_uwZ4UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "train_path = \"/content/full_synthetic_data_gpt_4o_5_dec\"\n",
        "\n",
        "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print('Dataset size:', len(data))"
      ],
      "metadata": {
        "id": "urvzkHUtaHGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(data)\n",
        "print('Dataset is shuffled...')\n",
        "\n",
        "train_dataset = data[:int(len(data)*0.8)]\n",
        "test_dataset = data[int(len(data)*0.8):]\n",
        "\n",
        "print('Dataset is split...')\n",
        "print('Train size:', len(train_dataset))\n",
        "print('Test size:', len(test_dataset))"
      ],
      "metadata": {
        "id": "dB0OZvfiaLOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the GLiNER model that you want to train on. In this case we will be using gliner-community/gliner_medium-v2.5**\n"
      ],
      "metadata": {
        "id": "cqzZfaVmaNub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gliner import GLiNER\n",
        "model = GLiNER.from_pretrained(\"gliner-community/gliner_medium-v2.5\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Wke6uqaraUMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollator(model.config, data_processor=model.data_processor, prepare_labels=True)\n",
        "model.to(device)\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "0vX9uhoJaW7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Start fine-tuning**\n",
        "\n",
        "The following code contains several parameters which will affect the resulting model in various ways. As this notebook is intended for experimentation, the number of epochs has been set at 500, but more may be needed to improve accuracy\n",
        "\n",
        "As the model proceeds with fine-tuning based on your data, it will log training and evaluation loss every 50 steps. All being well, these numbers should decrease as the model's accuracy improves with training"
      ],
      "metadata": {
        "id": "U-pDEzc8bRYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate number of epochs\n",
        "num_steps = 500\n",
        "batch_size = 8\n",
        "data_size = len(train_dataset)\n",
        "num_batches = data_size // batch_size\n",
        "num_epochs = max(1, num_steps // num_batches)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/models\",\n",
        "    learning_rate=5e-6,\n",
        "    weight_decay=0.01,\n",
        "    others_lr=1e-5,\n",
        "    others_weight_decay=0.01,\n",
        "    lr_scheduler_type=\"linear\", #cosine\n",
        "    warmup_ratio=0.1,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    eval_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    save_steps = 100,\n",
        "    save_total_limit=10,\n",
        "    dataloader_num_workers = 0,\n",
        "    use_cpu = False,\n",
        "    report_to=\"none\",\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=model.data_processor.transformer_tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "ktlLHXQ8b5MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the model**\n",
        "\n",
        "A few different 'checkpoints' (or versions) of the model will be saved in a file named 'models' in your directory. Based on the metrics you have observed above, you can save the version of the model with the best metrics (likely to be the one of the final checkpoints"
      ],
      "metadata": {
        "id": "HF7KV9Dob-xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = GLiNER.from_pretrained(\"/content/models/checkpoint-500\", load_tokenizer=True)"
      ],
      "metadata": {
        "id": "dC1AvgzMcbVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now test your trained model on a sample of text. In the code below, we test the model with some of the labels that were used in training:"
      ],
      "metadata": {
        "id": "LCwU0MAuce-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "The 19th century textile industry was a vibrant period of innovation and expansion, fueled by advancements in materials and techniques. Barwood, a natural dye source imported from Africa, played a crucial role in achieving rich red hues. Skilled colourists experimented with this and other natural dyes to create striking fabrics that met the era’s demand for color diversity.\n",
        "\n",
        "Processes like degumming were essential in preparing silk for dyeing and weaving, removing sericin to achieve a smooth finish. Similarly, scouring, the thorough cleaning of wool and other fibers, ensured that impurities did not interfere with dyeing or spinning processes. Innovations like the scotch feed mechanism improved efficiency in spinning mills, streamlining the delivery of fibers to machinery.\n",
        "\n",
        "Domett, a plain but durable cloth, was widely used for practical garments and household items, exemplifying the industry’s focus on both utility and style. These combined efforts shaped the thriving textile trade of the era.\n",
        "\"\"\"\n",
        "\n",
        "# Labels for entity prediction\n",
        "labels = [\"textile machinery\", \"textile fabric\", \"textile industry occupation\", \"textile dye\", \"textile manufacturing process\"]\n",
        "\n",
        "# Perform entity prediction\n",
        "entities = trained_model.predict_entities(text, labels, threshold=0.5)\n",
        "\n",
        "# Display predicted entities and their labels\n",
        "for entity in entities:\n",
        "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
      ],
      "metadata": {
        "id": "jtaavG-HcsoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Evaluate your model**"
      ],
      "metadata": {
        "id": "-hjQ91OQda8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can evaluate your model to see how it performs against any dataset of your choice. In this example we will evaluate it against the original training dataset.\n",
        "\n",
        "This will return the following metrics. The F1 score is the best standard to assess an NER model's accuracy:\n",
        "\n",
        "\n",
        "**P**: Precision (out of all entities identified, x% were correct)\n",
        "\n",
        "**tR**: Recall (number of actual positives identified by the model)\n",
        "\n",
        "**tF1**: A combination of Precision and Recall\n",
        "\n",
        "**n'**: F1 score as a decimal\n"
      ],
      "metadata": {
        "id": "FOmfZ8RYds-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "train_path = \"/content/your-dataset\"\n",
        "\n",
        "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print('Dataset size:', len(data))"
      ],
      "metadata": {
        "id": "JJVelzgGd1xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = model.evaluate(\n",
        "    data, flat_ner=True, entity_types=[\"textile manufacturing chemical\", \"textile dye\", \"textile machinery\", \"textile fibre\", \"textile fabric\", \"textile fabric component\", \"textile fabric imperfection\", \"textile waste material\", \"textile weave\", \"textile manufacturing process\", \"textile industry unit of measurement\", \"textile industry occupation\"]\n",
        ")"
      ],
      "metadata": {
        "id": "erDKSye7derG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Share your model to Huggingface**\n",
        "\n",
        "\n",
        "As runtimes delete automatically from Google Colab, you stand to lose your model unless you save it!\n",
        "\n",
        "It is a good idea to push the model to the Huggingface Hub - this means that you can safely use it subsequently any time you need it. This will require a (free) [Huggingface account](https://huggingface.co/)."
      ],
      "metadata": {
        "id": "WMYcvI8kc1RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "4NXiHmlGctaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "R0miH22edJVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model.push_to_hub(\"your_model_name\")"
      ],
      "metadata": {
        "id": "MwmVgeWmdLCk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}